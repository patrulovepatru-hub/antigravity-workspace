# GOAT â†’ CORLEONE
## Pipeline Multi-Modelo para AnÃ¡lisis de Audiencia

```
   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
  â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ•”â•â•â•
  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
  â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
   â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•   â•šâ•â•
         â””â”€â”€ CORLEONE (subproject)
```

## Objetivo
Pipeline automatizado: Instagram/LinkedIn â†’ anÃ¡lisis de audiencia â†’ insights accionables.

## ConfiguraciÃ³n Confirmada

| Recurso | Estado | Detalle |
|---------|--------|---------|
| **Cuenta Google** | âœ… | patriciomartinmendez@gmail.com |
| **Proyecto GCP** | âœ… | gen-lang-client-0988614926 |
| **Vertex AI API** | âœ… | Habilitado |
| **Gemini API** | âœ… | Habilitado |
| **Billing** | âœ… | Cuenta activa |
| **Sheets API** | ğŸ”„ | Por habilitar |

## Arquitectura HÃ­brida (VM + Host + Cloud)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            HOST WINDOWS 11                                  â”‚
â”‚                    64GB DDR5 | AMD 9060 XT 16GB                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ OLLAMA (Edge Computing)                                              â”‚   â”‚
â”‚  â”‚ - Pre-procesamiento local con GPU                                    â”‚   â”‚
â”‚  â”‚ - Modelos: llama3, mistral, phi3                                     â”‚   â”‚
â”‚  â”‚ - API: http://localhost:11434                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â–²                                              â”‚
â”‚                              â”‚ NAT/Bridge                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ VMware Ubuntu                                                        â”‚   â”‚
â”‚  â”‚ - Claude CLI (orquestaciÃ³n)                                          â”‚   â”‚
â”‚  â”‚ - EncriptaciÃ³n RSA                                                   â”‚   â”‚
â”‚  â”‚ - Scripts de pipeline                                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vertex AI       â”‚ â”€â”€â–º â”‚ Antigravity IDE  â”‚ â”€â”€â–º â”‚ Google Sheets   â”‚
â”‚ (Gemini Pro)    â”‚     â”‚ (EjecuciÃ³n)      â”‚     â”‚ (AlmacÃ©n)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos con Edge Computing

1. **Datos crudos** â†’ VM Ubuntu (encripta)
2. **Datos encriptados** â†’ Host Windows (Ollama pre-procesa)
3. **Datos filtrados** â†’ Vertex AI (Gemini analiza)
4. **Insights** â†’ Google Sheets (almacena)
5. **ValidaciÃ³n** â†’ Contrastar con datasets comprados (baseline)

## Estrategia de Datos: Baseline + Propios

### Fuentes de Datasets Baratos (usar crÃ©ditos)
| Fuente | Tipo de Datos | Costo Aprox |
|--------|---------------|-------------|
| **Kaggle** | Encuestas, trends | Gratis-$50 |
| **data.world** | Social media analytics | Gratis-$100 |
| **Statista** | Market research | $39/mes |
| **Google Dataset Search** | Diversos | Gratis |
| **AWS Data Exchange** | Comerciales | Variable |
| **Hugging Face Datasets** | NLP, sentiment | Gratis |

### Uso del Baseline
```
Datos propios (Instagram/LinkedIn)
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Compararâ”‚ â—„â”€â”€ Dataset comprado (baseline)
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   Insights validados
   (anomalÃ­as, tendencias confirmadas)
```

### Beneficios
- Validar si tus datos son representativos
- Detectar sesgos en tu audiencia
- Identificar tendencias que no estÃ¡s capturando
- Menor costo que estudios de mercado completos

## ImplementaciÃ³n por Fases

### Fase 1: Consolidar Google (Primero)
1. Elegir 1 cuenta maestra de Google
2. Vincular Vertex AI a esa cuenta
3. Crear proyecto GCP unificado
4. Habilitar APIs: Vertex AI, Sheets, BigQuery

### Fase 2: ExtracciÃ³n de Datos
**Instagram:**
- Meta Business Suite API (requiere cuenta business)
- Exportar insights de stories/posts

**LinkedIn:**
- LinkedIn Analytics export
- Sales Navigator si tienes

**Destino:** Google Sheets o BigQuery

### Fase 3: Pipeline de AnÃ¡lisis
```bash
# Desde Claude CLI (VMware Ubuntu)
# 1. Orquestar extracciÃ³n
claude "extraer datos de Instagram insights del Ãºltimo mes"

# 2. Enviar a Vertex AI para optimizar prompt
gcloud ai predict --model=gemini-pro --input="$DATOS"

# 3. Ejecutar en Antigravity con prompt optimizado
# 4. Guardar resultados en Sheets
```

### Fase 4: AutomatizaciÃ³n
- Google Apps Script para ejecuciÃ³n programada
- Alertas cuando hay nuevos insights relevantes

## Pasos de ImplementaciÃ³n

### Paso 1: Configurar proyecto GCP (terminal)
```bash
gcloud config set project gen-lang-client-0988614926
gcloud services enable sheets.googleapis.com
```

### Paso 2: Crear Service Account
```bash
gcloud iam service-accounts create pipeline-bot \
  --display-name="Pipeline AnÃ¡lisis Audiencia"
gcloud iam service-accounts keys create ~/pipeline-key.json \
  --iam-account=pipeline-bot@gen-lang-client-0988614926.iam.gserviceaccount.com
```

### Paso 3: Crear script de conexiÃ³n Claude â†’ Gemini
Archivo: `/home/patricio/pipeline/gemini-prompt.sh`
- Recibe datos de Instagram/LinkedIn
- Llama a Gemini para optimizar prompt
- Retorna prompt optimizado para Antigravity

### Paso 4: Configurar Google Sheet central
- Crear spreadsheet "AnÃ¡lisis Audiencia"
- Columnas: Fecha | Fuente | Datos Crudos | Prompt Optimizado | Insights

### Paso 5: Script orquestador
Archivo: `/home/patricio/pipeline/run-pipeline.sh`
- Input: datos de encuestas
- Output: insights en Sheets

## VerificaciÃ³n
1. Ejecutar `gcloud ai models list` - debe mostrar modelos Gemini
2. Probar llamada a Gemini con prompt simple
3. Verificar escritura en Google Sheets

## Progreso Actual

### Completado
- [x] gcloud CLI instalado y autenticado
- [x] Proyecto GCP configurado: `gen-lang-client-0988614926`
- [x] Sheets API habilitada
- [x] Service Account creada: `pipeline-bot`
- [x] EncriptaciÃ³n RSA 4096-bit implementada
- [x] Scripts creados:
  - `/home/patricio/pipeline/encrypt.sh`
  - `/home/patricio/pipeline/decrypt.sh`
  - `/home/patricio/pipeline/run-pipeline.sh`
  - `/home/patricio/pipeline/config.env`
  - `/home/patricio/pipeline/keys/` (llaves RSA)

### Pendiente
- [ ] Configurar OAuth para Gemini (sin API key)
- [ ] Configurar Ollama en Host Windows (64GB RAM, 9060 XT)
- [ ] Test end-to-end: datos â†’ Ollama â†’ Gemini â†’ Sheets

## AutenticaciÃ³n OAuth (en lugar de API Key)

Para usar OAuth con Gemini:
```bash
gcloud auth application-default login \
  --scopes="https://www.googleapis.com/auth/generative-language.retriever,https://www.googleapis.com/auth/cloud-platform"
```

Luego visitar el URL generado en navegador y pegar el cÃ³digo de verificaciÃ³n.

## Estructura Actual

```
/home/patricio/pipeline/
â”œâ”€â”€ GOAT (proyecto padre)
â”‚   â”œâ”€â”€ encrypt.sh / decrypt.sh    âœ… RSA 4096-bit
â”‚   â”œâ”€â”€ cache.sh                   âœ… CachÃ© respuestas
â”‚   â”œâ”€â”€ preprocess.sh              âœ… Limpieza local
â”‚   â”œâ”€â”€ ollama-client.sh           âœ… ConexiÃ³n a Host
â”‚   â”œâ”€â”€ gemini-client.sh           âœ… API Gemini
â”‚   â”œâ”€â”€ run-pipeline.sh            âœ… Orquestador
â”‚   â””â”€â”€ keys/                      âœ… Llaves + Service Account
â”‚
â””â”€â”€ corleone/ (subproyecto activo)
    â”œâ”€â”€ config.env                 âœ… ConfiguraciÃ³n
    â”œâ”€â”€ gemini.sh                  âœ… Cliente simplificado
    â”œâ”€â”€ bridge.sh                  âœ… ConexiÃ³n Antigravity
    â”œâ”€â”€ data/                      ğŸ“ Datos entrada
    â”œâ”€â”€ prompts/                   ğŸ“ Prompts guardados
    â”œâ”€â”€ outputs/                   ğŸ“ Resultados
    â”‚
    â””â”€â”€ 4exe/                      ğŸ†• Forensic Toolkit
        â”œâ”€â”€ 4exe.sh                CLI principal
        â”œâ”€â”€ evidence/              Datos para anÃ¡lisis
        â””â”€â”€ reports/               Reportes generados

## 4EXE (FORENSIC) - Data Analysis Toolkit

```
patru = 4 | exe = executable | 4ensic = forensic
@patru = cuenta Instagram del owner
```

### Funcionalidades
1. **analyze** - AnÃ¡lisis forense de archivos/datos
2. **extract** - Extraer entidades (emails, IPs, URLs, hashes)
3. **ai** - AnÃ¡lisis inteligente con LM Studio
4. **hash** - Calcular checksums
5. **timeline** - Timeline de archivos
6. **social** - AnÃ¡lisis de redes sociales
```

## ConfiguraciÃ³n Host Windows (LM Studio)

### Modelo seleccionado
- **Llama 3 8B** - Balance Ã³ptimo para 16GB VRAM

### Configurar LM Studio para acceso remoto

1. Abrir LM Studio
2. Cargar modelo: `Llama 3 8B` (Q4_K_M o Q5_K_M)
3. Ir a **Local Server** tab
4. Activar **"Enable CORS"**
5. Cambiar puerto si es necesario (default: 1234)
6. Click **Start Server**

### Firewall Windows
```powershell
netsh advfirewall firewall add rule name="LM Studio API" dir=in action=allow protocol=tcp localport=1234
```

### API de LM Studio (compatible con OpenAI)
```bash
# Desde VM Ubuntu
curl http://192.168.192.2:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "local-model",
    "messages": [{"role": "user", "content": "Analiza estos datos..."}]
  }'
```

### Endpoint
- **URL:** `http://192.168.192.2:1234/v1`
- **Modelo:** `local-model` (LM Studio usa este nombre genÃ©rico)

## FASE 2: Infraestructura Distribuida

### Arquitectura Multi-MÃ¡quina
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RELAY PRIVADA SEGURA                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  VM Ubuntu (Orquestador)                                        â”‚
â”‚  â”œâ”€â”€ Claude CLI                                                 â”‚
â”‚  â”œâ”€â”€ Logs auditables (CÃ¡mara Comercio)                         â”‚
â”‚  â”œâ”€â”€ EncriptaciÃ³n E2E                                          â”‚
â”‚  â””â”€â”€ Load Balancer                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Windows Host (Compute)                                         â”‚
â”‚  â”œâ”€â”€ LM Studio (Llama 3 8B) :1234                              â”‚
â”‚  â”œâ”€â”€ Antigravity IDE                                           â”‚
â”‚  â””â”€â”€ GPU Processing                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Cloud (Overflow)                                               â”‚
â”‚  â”œâ”€â”€ Vertex AI / Gemini                                        â”‚
â”‚  â””â”€â”€ Google Sheets (Storage)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Logging para Compliance (CÃ¡mara de Comercio)
- Timestamps ISO 8601
- Hash de cada transacciÃ³n
- Firma digital de logs
- RetenciÃ³n configurable
- Exportable a PDF/JSON

### Sharding y Overflow
```
Request â†’ Load Balancer
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼         â–¼         â–¼
 LM Studio  Gemini   Overflow
 (local)    (cloud)  (queue)
```

## Archivos a crear - Fase 2
- `/home/patricio/pipeline/relay/relay.sh` - Relay segura
- `/home/patricio/pipeline/logs/audit.sh` - Logging compliance
- `/home/patricio/pipeline/lb/balancer.sh` - Load balancer
- `/home/patricio/pipeline/debug/debug.sh` - Debugger
